{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time,datetime\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from IPython import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import transform as T\n",
    "from torch.utils.data import DataLoader\n",
    "from model.ReIDNet import ReIDNet\n",
    "from dataset_manager import Market1501\n",
    "from dataset_loader import ImageDataset\n",
    "from distance import low_memory_local_dist\n",
    "from eval_metrics import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设定输入参数\n",
    "width=64                    #图片宽度\n",
    "height=128                 #图片高度\n",
    "batch_size=32  #训练批量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, queryloader, galleryloader,ranks=[1, 5, 10, 20]):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        qf, q_pids, q_camids= [], [], []\n",
    "        for batch_idx, (imgs, pids, camids) in enumerate(queryloader):\n",
    "            features = model(imgs)\n",
    "            qf.append(features)\n",
    "            q_pids.extend(pids)\n",
    "            q_camids.extend(camids)\n",
    "        qf = torch.cat(qf, 0)\n",
    "        q_pids = np.asarray(q_pids)\n",
    "        q_camids = np.asarray(q_camids)\n",
    "        print(\"Extracted features for query set, obtained {}-by-{} matrix\".format(qf.size(0), qf.size(1)))\n",
    "\n",
    "        gf, g_pids, g_camids = [], [], []\n",
    "        for batch_idx, (imgs, pids, camids) in enumerate(galleryloader):\n",
    "            features= model(imgs)\n",
    "            gf.append(features)\n",
    "            g_pids.extend(pids)\n",
    "            g_camids.extend(camids)\n",
    "        gf = torch.cat(gf, 0)\n",
    "        g_pids = np.asarray(g_pids)\n",
    "        g_camids = np.asarray(g_camids)\n",
    "        print(\"Extracted features for gallery set, obtained {}-by-{} matrix\".format(gf.size(0), gf.size(1)))\n",
    "\n",
    "    # feature normlization\n",
    "    qf = 1. * qf / (torch.norm(qf, 2, dim = -1, keepdim=True).expand_as(qf) + 1e-12)\n",
    "    gf = 1. * gf / (torch.norm(gf, 2, dim = -1, keepdim=True).expand_as(gf) + 1e-12)\n",
    "    m, n = qf.size(0), gf.size(0)\n",
    "    distmat = torch.pow(qf, 2).sum(dim=1, keepdim=True).expand(m, n) + \\\n",
    "              torch.pow(gf, 2).sum(dim=1, keepdim=True).expand(n, m).t()\n",
    "    distmat.addmm_(1, -2, qf, gf.t())\n",
    "    distmat = distmat.numpy()\n",
    "    \n",
    "    print(\"Using global features\")\n",
    "    print(\"Computing CMC and mAP\")\n",
    "    cmc, mAP = evaluate(distmat, q_pids, g_pids, q_camids, g_camids)\n",
    "\n",
    "    print(\"Results ----------\")\n",
    "    print(\"mAP: {:.1%}\".format(mAP))\n",
    "    print(\"CMC curve\")\n",
    "    for r in ranks:\n",
    "        print(\"Rank-{:<3}: {:.1%}\".format(r, cmc[r - 1]))\n",
    "    print(\"------------------\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Market1501 loaded\n",
      "------------------------------------------------------------------------\n",
      "  subset: train  \t| num_id:   751  \t|  num_imgs:   12936  \n",
      "  subset: query  \t| num_id:   750  \t|  num_imgs:    3368  \n",
      "  subset: gallery \t| num_id:   751  \t|  num_imgs:   19732  \n",
      "------------------------------------------------------------------------\n",
      "  total \t\t\t| num_id:  1501  \t|  num_imgs:   16304  \n",
      "------------------------------------------------------------------------\n",
      "Extracted features for query set, obtained 3360-by-2048 matrix\n",
      "Extracted features for gallery set, obtained 15904-by-2048 matrix\n",
      "Using global features\n",
      "Computing CMC and mAP\n",
      "Results ----------\n",
      "mAP: 0.4%\n",
      "CMC curve\n",
      "Rank-1  : 0.6%\n",
      "Rank-5  : 2.0%\n",
      "Rank-10 : 3.6%\n",
      "Rank-20 : 6.3%\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    model=ReIDNet(num_classes=751,loss='softmax')\n",
    "    model.load_state_dict(torch.load('./model/net_params.pkl'))\n",
    "    dataset=Market1501()\n",
    "    #训练数据处理器\n",
    "    transform=T.Compose([\n",
    "        T.Resize((height,width)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    "    )\n",
    "    #train数据集吞吐器\n",
    "    query_data_loader=DataLoader(\n",
    "        ImageDataset(dataset.query, transform=transform),\n",
    "        batch_size=batch_size,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    #train数据集吞吐器\n",
    "    gallery_data_loader=DataLoader(\n",
    "        ImageDataset(dataset.gallery, transform=transform),\n",
    "        batch_size=batch_size,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    test(model,query_data_loader,gallery_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def test(model, queryloader, galleryloader, use_gpu, ranks=[1, 5, 10, 20]):\n",
    "    batch_time = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        qf, q_pids, q_camids, lqf = [], [], [], []\n",
    "        for batch_idx, (imgs, pids, camids) in enumerate(queryloader):\n",
    "            if use_gpu: imgs = imgs.cuda()\n",
    "\n",
    "            end = time.time()\n",
    "            features, local_features = model(imgs)\n",
    "            batch_time.update(time.time() - end)\n",
    "\n",
    "            features = features.data.cpu()\n",
    "            local_features = local_features.data.cpu()\n",
    "            qf.append(features)\n",
    "            lqf.append(local_features)\n",
    "            q_pids.extend(pids)\n",
    "            q_camids.extend(camids)\n",
    "        qf = torch.cat(qf, 0)\n",
    "        lqf = torch.cat(lqf,0)\n",
    "        q_pids = np.asarray(q_pids)\n",
    "        q_camids = np.asarray(q_camids)\n",
    "\n",
    "        print(\"Extracted features for query set, obtained {}-by-{} matrix\".format(qf.size(0), qf.size(1)))\n",
    "\n",
    "        gf, g_pids, g_camids, lgf = [], [], [], []\n",
    "        end = time.time()\n",
    "        for batch_idx, (imgs, pids, camids) in enumerate(galleryloader):\n",
    "            if use_gpu: imgs = imgs.cuda()\n",
    "\n",
    "            end = time.time()\n",
    "            features, local_features = model(imgs)\n",
    "            batch_time.update(time.time() - end)\n",
    "\n",
    "            features = features.data.cpu()\n",
    "            local_features = local_features.data.cpu()\n",
    "            gf.append(features)\n",
    "            lgf.append(local_features)\n",
    "            g_pids.extend(pids)\n",
    "            g_camids.extend(camids)\n",
    "        gf = torch.cat(gf, 0)\n",
    "        lgf = torch.cat(lgf,0)\n",
    "        g_pids = np.asarray(g_pids)\n",
    "        g_camids = np.asarray(g_camids)\n",
    "\n",
    "\n",
    "        print(\"Extracted features for gallery set, obtained {}-by-{} matrix\".format(gf.size(0), gf.size(1)))\n",
    "\n",
    "    print(\"==> BatchTime(s)/BatchSize(img): {:.3f}/{}\".format(batch_time.avg, args.test_batch))\n",
    "    # feature normlization\n",
    "    qf = 1. * qf / (torch.norm(qf, 2, dim = -1, keepdim=True).expand_as(qf) + 1e-12)\n",
    "    gf = 1. * gf / (torch.norm(gf, 2, dim = -1, keepdim=True).expand_as(gf) + 1e-12)\n",
    "    m, n = qf.size(0), gf.size(0)\n",
    "    distmat = torch.pow(qf, 2).sum(dim=1, keepdim=True).expand(m, n) + \\\n",
    "              torch.pow(gf, 2).sum(dim=1, keepdim=True).expand(n, m).t()\n",
    "    distmat.addmm_(1, -2, qf, gf.t())\n",
    "    distmat = distmat.numpy()\n",
    "\n",
    "    if not args.test_distance== 'global':\n",
    "        print(\"Only using global branch\")\n",
    "        from util.distance import low_memory_local_dist\n",
    "        lqf = lqf.permute(0,2,1)\n",
    "        lgf = lgf.permute(0,2,1)\n",
    "        local_distmat = low_memory_local_dist(lqf.numpy(),lgf.numpy(),aligned= not args.unaligned)\n",
    "        if args.test_distance== 'local':\n",
    "            print(\"Only using local branch\")\n",
    "            distmat = local_distmat\n",
    "        if args.test_distance == 'global_local':\n",
    "            print(\"Using global and local branches\")\n",
    "            distmat = local_distmat+distmat\n",
    "    print(\"Computing CMC and mAP\")\n",
    "    cmc, mAP = evaluate(distmat, q_pids, g_pids, q_camids, g_camids, use_metric_cuhk03=args.use_metric_cuhk03)\n",
    "\n",
    "    print(\"Results ----------\")\n",
    "    print(\"mAP: {:.1%}\".format(mAP))\n",
    "    print(\"CMC curve\")\n",
    "    for r in ranks:\n",
    "        print(\"Rank-{:<3}: {:.1%}\".format(r, cmc[r - 1]))\n",
    "    print(\"------------------\")\n",
    "\n",
    "    if args.reranking:\n",
    "        from util.re_ranking import re_ranking\n",
    "        if args.test_distance == 'global':\n",
    "            print(\"Only using global branch for reranking\")\n",
    "            distmat = re_ranking(qf,gf,k1=20, k2=6, lambda_value=0.3)\n",
    "        else:\n",
    "            local_qq_distmat = low_memory_local_dist(lqf.numpy(), lqf.numpy(),aligned= not args.unaligned)\n",
    "            local_gg_distmat = low_memory_local_dist(lgf.numpy(), lgf.numpy(),aligned= not args.unaligned)\n",
    "            local_dist = np.concatenate(\n",
    "                [np.concatenate([local_qq_distmat, local_distmat], axis=1),\n",
    "                 np.concatenate([local_distmat.T, local_gg_distmat], axis=1)],\n",
    "                axis=0)\n",
    "            if args.test_distance == 'local':\n",
    "                print(\"Only using local branch for reranking\")\n",
    "                distmat = re_ranking(qf,gf,k1=20,k2=6,lambda_value=0.3,local_distmat=local_dist,only_local=True)\n",
    "            elif args.test_distance == 'global_local':\n",
    "                print(\"Using global and local branches for reranking\")\n",
    "                distmat = re_ranking(qf,gf,k1=20,k2=6,lambda_value=0.3,local_distmat=local_dist,only_local=False)\n",
    "        print(\"Computing CMC and mAP for re_ranking\")\n",
    "        cmc, mAP = evaluate(distmat, q_pids, g_pids, q_camids, g_camids, use_metric_cuhk03=args.use_metric_cuhk03)\n",
    "\n",
    "        print(\"Results ----------\")\n",
    "        print(\"mAP(RK): {:.1%}\".format(mAP))\n",
    "        print(\"CMC curve(RK)\")\n",
    "        for r in ranks:\n",
    "            print(\"Rank-{:<3}: {:.1%}\".format(r, cmc[r - 1]))\n",
    "        print(\"------------------\")\n",
    "    return cmc[0]\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
