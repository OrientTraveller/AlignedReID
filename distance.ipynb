{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(nparray, order=2, axis=0):\n",
    "    \"\"\"Normalize a N-D numpy array along the specified axis.\"\"\"\n",
    "    norm = np.linalg.norm(nparray, ord=order, axis=axis, keepdims=True)\n",
    "    return nparray / (norm + np.finfo(np.float32).eps)\n",
    "\n",
    "\n",
    "def compute_dist(array1, array2, type='euclidean'):\n",
    "    \"\"\"Compute the euclidean or cosine distance of all pairs.\n",
    "  Args:\n",
    "    array1: numpy array with shape [m1, n]\n",
    "    array2: numpy array with shape [m2, n]\n",
    "    type: one of ['cosine', 'euclidean']\n",
    "  Returns:\n",
    "    numpy array with shape [m1, m2]\n",
    "  \"\"\"\n",
    "    assert type in ['cosine', 'euclidean']\n",
    "    if type == 'cosine':\n",
    "        array1 = normalize(array1, axis=1)\n",
    "        array2 = normalize(array2, axis=1)\n",
    "        dist = np.matmul(array1, array2.T)\n",
    "        return dist\n",
    "    else:\n",
    "        # shape [m1, 1]\n",
    "        square1 = np.sum(np.square(array1), axis=1)[..., np.newaxis]\n",
    "        # shape [1, m2]\n",
    "        square2 = np.sum(np.square(array2), axis=1)[np.newaxis, ...]\n",
    "        squared_dist = - 2 * np.matmul(array1, array2.T) + square1 + square2\n",
    "        squared_dist[squared_dist < 0] = 0\n",
    "        dist = np.sqrt(squared_dist)\n",
    "        return dist\n",
    "\n",
    "\n",
    "def shortest_dist(dist_mat):\n",
    "    \"\"\"Parallel version.\n",
    "  Args:\n",
    "    dist_mat: numpy array, available shape\n",
    "      1) [m, n]\n",
    "      2) [m, n, N], N is batch size\n",
    "      3) [m, n, *], * can be arbitrary additional dimensions\n",
    "  Returns:\n",
    "    dist: three cases corresponding to `dist_mat`\n",
    "      1) scalar\n",
    "      2) numpy array, with shape [N]\n",
    "      3) numpy array with shape [*]\n",
    "  \"\"\"\n",
    "    m, n = dist_mat.shape[:2]\n",
    "    dist = np.zeros_like(dist_mat)\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if (i == 0) and (j == 0):\n",
    "                dist[i, j] = dist_mat[i, j]\n",
    "            elif (i == 0) and (j > 0):\n",
    "                dist[i, j] = dist[i, j - 1] + dist_mat[i, j]\n",
    "            elif (i > 0) and (j == 0):\n",
    "                dist[i, j] = dist[i - 1, j] + dist_mat[i, j]\n",
    "            else:\n",
    "                dist[i, j] = \\\n",
    "                    np.min(np.stack([dist[i - 1, j], dist[i, j - 1]], axis=0), axis=0) \\\n",
    "                    + dist_mat[i, j]\n",
    "    # I ran into memory disaster when returning this reference! I still don't\n",
    "    # know why.\n",
    "    # dist = dist[-1, -1]\n",
    "    dist = dist[-1, -1].copy()\n",
    "    return dist\n",
    "\n",
    "def unaligned_dist(dist_mat):\n",
    "    \"\"\"Parallel version.\n",
    "    Args:\n",
    "      dist_mat: numpy array, available shape\n",
    "        1) [m, n]\n",
    "        2) [m, n, N], N is batch size\n",
    "        3) [m, n, *], * can be arbitrary additional dimensions\n",
    "    Returns:\n",
    "      dist: three cases corresponding to `dist_mat`\n",
    "        1) scalar\n",
    "        2) numpy array, with shape [N]\n",
    "        3) numpy array with shape [*]\n",
    "    \"\"\"\n",
    "\n",
    "    m = dist_mat.shape[0]\n",
    "    dist = np.zeros_like(dist_mat[0])\n",
    "    for i in range(m):\n",
    "        dist[i] = dist_mat[i][i]\n",
    "    dist = np.sum(dist, axis=0).copy()\n",
    "    return dist\n",
    "\n",
    "\n",
    "def meta_local_dist(x, y, aligned):\n",
    "    \"\"\"\n",
    "  Args:\n",
    "    x: numpy array, with shape [m, d]\n",
    "    y: numpy array, with shape [n, d]\n",
    "  Returns:\n",
    "    dist: scalar\n",
    "  \"\"\"\n",
    "    eu_dist = compute_dist(x, y, 'euclidean')\n",
    "    dist_mat = (np.exp(eu_dist) - 1.) / (np.exp(eu_dist) + 1.)\n",
    "    if aligned:\n",
    "        dist = shortest_dist(dist_mat[np.newaxis])[0]\n",
    "    else:\n",
    "        dist = unaligned_dist(dist_mat[np.newaxis])[0]\n",
    "    return dist\n",
    "\n",
    "\n",
    "# Tooooooo slow!\n",
    "def serial_local_dist(x, y):\n",
    "    \"\"\"\n",
    "  Args:\n",
    "    x: numpy array, with shape [M, m, d]\n",
    "    y: numpy array, with shape [N, n, d]\n",
    "  Returns:\n",
    "    dist: numpy array, with shape [M, N]\n",
    "  \"\"\"\n",
    "    M, N = x.shape[0], y.shape[0]\n",
    "    dist_mat = np.zeros([M, N])\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            dist_mat[i, j] = meta_local_dist(x[i], y[j])\n",
    "    return dist_mat\n",
    "\n",
    "\n",
    "def parallel_local_dist(x, y, aligned):\n",
    "    \"\"\"Parallel version.\n",
    "  Args:\n",
    "    x: numpy array, with shape [M, m, d]\n",
    "    y: numpy array, with shape [N, n, d]\n",
    "  Returns:\n",
    "    dist: numpy array, with shape [M, N]\n",
    "  \"\"\"\n",
    "    M, m, d = x.shape\n",
    "    N, n, d = y.shape\n",
    "    x = x.reshape([M * m, d])\n",
    "    y = y.reshape([N * n, d])\n",
    "    # shape [M * m, N * n]\n",
    "    dist_mat = compute_dist(x, y, type='euclidean')\n",
    "    dist_mat = (np.exp(dist_mat) - 1.) / (np.exp(dist_mat) + 1.)\n",
    "    # shape [M * m, N * n] -> [M, m, N, n] -> [m, n, M, N]\n",
    "    dist_mat = dist_mat.reshape([M, m, N, n]).transpose([1, 3, 0, 2])\n",
    "    # shape [M, N]\n",
    "    if aligned:\n",
    "        dist_mat = shortest_dist(dist_mat)\n",
    "    else:\n",
    "        dist_mat = unaligned_dist(dist_mat)\n",
    "    return dist_mat\n",
    "\n",
    "\n",
    "def local_dist(x, y, aligned):\n",
    "    if (x.ndim == 2) and (y.ndim == 2):\n",
    "        return meta_local_dist(x, y, aligned)\n",
    "    elif (x.ndim == 3) and (y.ndim == 3):\n",
    "        return parallel_local_dist(x, y, aligned)\n",
    "    else:\n",
    "        raise NotImplementedError('Input shape not supported.')\n",
    "\n",
    "\n",
    "def low_memory_matrix_op(\n",
    "        func,\n",
    "        x, y,\n",
    "        x_split_axis, y_split_axis,\n",
    "        x_num_splits, y_num_splits,\n",
    "        verbose=False, aligned=True):\n",
    "    \"\"\"\n",
    "  For matrix operation like multiplication, in order not to flood the memory\n",
    "  with huge data, split matrices into smaller parts (Divide and Conquer).\n",
    "  Note:\n",
    "    If still out of memory, increase `*_num_splits`.\n",
    "  Args:\n",
    "    func: a matrix function func(x, y) -> z with shape [M, N]\n",
    "    x: numpy array, the dimension to split has length M\n",
    "    y: numpy array, the dimension to split has length N\n",
    "    x_split_axis: The axis to split x into parts\n",
    "    y_split_axis: The axis to split y into parts\n",
    "    x_num_splits: number of splits. 1 <= x_num_splits <= M\n",
    "    y_num_splits: number of splits. 1 <= y_num_splits <= N\n",
    "    verbose: whether to print the progress\n",
    "  Returns:\n",
    "    mat: numpy array, shape [M, N]\n",
    "  \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        import sys\n",
    "        import time\n",
    "        printed = False\n",
    "        st = time.time()\n",
    "        last_time = time.time()\n",
    "\n",
    "    mat = [[] for _ in range(x_num_splits)]\n",
    "    for i, part_x in enumerate(\n",
    "            np.array_split(x, x_num_splits, axis=x_split_axis)):\n",
    "        for j, part_y in enumerate(\n",
    "                np.array_split(y, y_num_splits, axis=y_split_axis)):\n",
    "            part_mat = func(part_x, part_y, aligned)\n",
    "            mat[i].append(part_mat)\n",
    "\n",
    "            if verbose:\n",
    "                if not printed:\n",
    "                    printed = True\n",
    "                else:\n",
    "                    # Clean the current line\n",
    "                    sys.stdout.write(\"\\033[F\\033[K\")\n",
    "                print('Matrix part ({}, {}) / ({}, {}), +{:.2f}s, total {:.2f}s'\n",
    "                    .format(i + 1, j + 1, x_num_splits, y_num_splits,\n",
    "                            time.time() - last_time, time.time() - st))\n",
    "                last_time = time.time()\n",
    "        mat[i] = np.concatenate(mat[i], axis=1)\n",
    "    mat = np.concatenate(mat, axis=0)\n",
    "    return mat\n",
    "\n",
    "\n",
    "def low_memory_local_dist(x, y, aligned=True):\n",
    "    print('Computing local distance...')\n",
    "    x_num_splits = int(len(x) / 200) + 1\n",
    "    y_num_splits = int(len(y) / 200) + 1\n",
    "    z = low_memory_matrix_op(local_dist, x, y, 0, 0, x_num_splits, y_num_splits, verbose=False, aligned=aligned)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing local distance...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.07097652]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_memory_local_dist([[[1,3],[3,4]]],[[[2,3],[3,4]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
